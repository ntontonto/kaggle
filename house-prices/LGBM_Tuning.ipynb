{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44b3e9e1c0a948f2a5790a16d265b2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a192e28e95284fc0a57789b9866fd5ba",
              "IPY_MODEL_f9c2acc03fef48479d95197ac620e477",
              "IPY_MODEL_6d73ddc3990144ccad3dab5e5d2d7186"
            ],
            "layout": "IPY_MODEL_b44154088f994c0caf51e5ee3d36ae68"
          }
        },
        "a192e28e95284fc0a57789b9866fd5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc674aa2c616440d85541dc0706be3f6",
            "placeholder": "​",
            "style": "IPY_MODEL_11ebc3fc9cc74adfa2e226cc87a9d77e",
            "value": "Best trial: 20. Best value: 27925.7: 100%"
          }
        },
        "f9c2acc03fef48479d95197ac620e477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05aa7cedc4c94e179adb2d50aa2c6660",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b548763d0da4b14bdcb492d226e6429",
            "value": 50
          }
        },
        "6d73ddc3990144ccad3dab5e5d2d7186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55130a55aee242af89815598b46ade5a",
            "placeholder": "​",
            "style": "IPY_MODEL_a237c67215794aeea59cca4f0c85a3b4",
            "value": " 50/50 [02:27&lt;00:00,  3.06s/it]"
          }
        },
        "b44154088f994c0caf51e5ee3d36ae68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc674aa2c616440d85541dc0706be3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ebc3fc9cc74adfa2e226cc87a9d77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05aa7cedc4c94e179adb2d50aa2c6660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b548763d0da4b14bdcb492d226e6429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55130a55aee242af89815598b46ade5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a237c67215794aeea59cca4f0c85a3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量のカンペはこちら ⇒ https://docs.google.com/spreadsheets/d/1T59ieP110cFg8MfOtIbW2M60iWuSwnIf/edit?usp=share_link&ouid=111727008586725963366&rtpof=true&sd=true"
      ],
      "metadata": {
        "id": "AXi4WtN9fjQh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4PtisoVRRWv"
      },
      "source": [
        "## Kaggle用データのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4dUr5pkUwu0U",
        "outputId": "6b79ba02-3f18-4c5d-957a-08084c5bad59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c65c8b73-ec32-4c38-b6f0-f56c8c7e11cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c65c8b73-ec32-4c38-b6f0-f56c8c7e11cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"droeloe\",\"key\":\"c330037c8e955090c87e6872ec333b32\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "COMPETITION = \"house-prices-advanced-regression-techniques\"\n",
        "WORK_DIR = \"/content/drive/MyDrive/Colab Notebooks/kaggle\"\n",
        "\n",
        "import os\n",
        "\n",
        "if not(os.path.exists(WORK_DIR)):\n",
        "  os.mkdir(WORK_DIR)\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejol7bfVxlgQ",
        "outputId": "e214bc7e-c5d3-4295-ef5b-a1b4931c6886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading house-prices-advanced-regression-techniques.zip to /content/drive/MyDrive/Colab Notebooks/kaggle\n",
            "\r  0% 0.00/199k [00:00<?, ?B/s]\n",
            "\r100% 199k/199k [00:00<00:00, 24.8MB/s]\n",
            "Archive:  house-prices-advanced-regression-techniques.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c {COMPETITION} # copy from competition page!\n",
        "!unzip -o {COMPETITION}\n",
        "!rm {COMPETITION}.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QuY8halx1Op"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "Qwl5SkWexlu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001c4238-e0e7-4161-9d07-c1781234c44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "from numpy import mean, std\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats import power\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "import math\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "\n",
        "PALETTE=['lightcoral', 'lightskyblue', 'gold', 'sandybrown', 'navajowhite',\n",
        "        'khaki', 'lightslategrey', 'turquoise', 'rosybrown', 'thistle', 'pink']\n",
        "sns.set_palette(PALETTE) # seabornのデフォルトの色を変更する\n",
        "BACKCOLOR = '#f6f5f5'\n",
        "\n",
        "from scipy.special import boxcox1p\n",
        "from IPython.core.display import HTML\n",
        "from scipy.stats import norm, skew #for some statistics\n",
        "import missingno as msno\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from scipy.stats import skew, boxcox_normmax\n",
        "from scipy.special import boxcox1p\n",
        "\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from copy import deepcopy\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvnspI2dk6Vi"
      },
      "source": [
        "### User modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p1WYzSjVyzxG"
      },
      "outputs": [],
      "source": [
        "# 並び替え検定用の関数\n",
        "def perm_fun(x, nA, nB):\n",
        "    n = nA + nB\n",
        "    idx_B = set(random.sample(range(n), nB))\n",
        "    idx_A = set(range(n)) - idx_B\n",
        "    return x.loc[list(idx_B)].mean() - x.loc[list(idx_A)].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PK8K5v9jvW-2"
      },
      "outputs": [],
      "source": [
        "# permutation test\n",
        "def permutation_test(data, var, target):\n",
        "\n",
        "  vA = data[var].dropna().unique()[0]\n",
        "  vB = data[var].dropna().unique()[1]\n",
        "  mean_a = data[data[var] == vA][target].mean()\n",
        "  mean_b = data[data[var] == vB][target].mean()\n",
        "  print(f\"{target} mean value with {var}={vA}: {mean_a}\")\n",
        "  print(f\"{target} mean value with {var}={vB}: {mean_b}\")\n",
        "  print(f\"{target} observed difference between ({var}={vA}) and ({var}={vB}): {mean_b - mean_a}\")\n",
        "  nA = data[data[var] == vA].shape[0]\n",
        "  nB = data[data[var] == vB].shape[0]\n",
        "\n",
        "  random.seed(1)\n",
        "  perm_diffs = pd.Series([perm_fun(data[target], nA, nB) for _ in range(1000)])\n",
        "  perm_diffs = perm_diffs.dropna()\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(5, 5))\n",
        "  ax.hist(perm_diffs, bins=11, rwidth=0.9)\n",
        "  ax.axvline(x = mean_b - mean_a, color='black', lw=2)\n",
        "  ax.text(mean_b - mean_a, 10, 'Observed\\ndifference', bbox={'facecolor':'white'})\n",
        "  ax.set_xlabel(f'{var} differences')\n",
        "  ax.set_ylabel('Frequency')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  perm_diffs = np.array(perm_diffs)\n",
        "  print('p-value: ', (np.mean(perm_diffs > mean_b - mean_a)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uwS3lLWzQcLp"
      },
      "outputs": [],
      "source": [
        "def multi_table(table_list):\n",
        "    return HTML(\n",
        "        f\"<table><tr> {''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list])} </tr></table>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O1IzxNO-Qg_z"
      },
      "outputs": [],
      "source": [
        "def cat_dist(data, var, hue, msg_show=True):\n",
        "    total_cnt = data[var].count()\n",
        "    f, ax = plt.subplots(1, 2, figsize=(25, 8))\n",
        "    hues = [None, hue]\n",
        "    titles = [f\"{var}'s distribution\", f\"{var}'s distribution by {hue}\"]\n",
        "\n",
        "    for i in range(2):\n",
        "        sns.countplot(data[var], edgecolor='black', hue=hues[i], linewidth=1, ax=ax[i], data=data)\n",
        "        ax[i].set_xlabel(var, weight='bold', size=13)\n",
        "        ax[i].set_ylabel('Count', weight='bold', size=13)\n",
        "        ax[i].set_facecolor(BACKCOLOR)\n",
        "        ax[i].spines['top'].set_visible(False)\n",
        "        ax[i].spines['right'].set_visible(False)\n",
        "        ax[i].set_title(titles[i], size=15, weight='bold')\n",
        "        for patch in ax[i].patches:\n",
        "            x, height, width = patch.get_x(), patch.get_height(), patch.get_width()\n",
        "            if msg_show:\n",
        "                ax[i].text(x + width / 2, height + 3, f'{height} \\n({height / total_cnt * 100:2.2f}%)', va='center', ha='center', size=12, bbox={'facecolor': 'white', 'boxstyle': 'round'})\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TIrhiw56QkPc"
      },
      "outputs": [],
      "source": [
        "def continuous_dist(data, x, y):\n",
        "    f, ax = plt.subplots(1, 4, figsize=(35, 10))\n",
        "    sns.histplot(data=train, x=y, hue=x, ax=ax[0], element='step')\n",
        "    sns.violinplot(x=data[x], y=data[y], ax=ax[1], edgecolor='black', linewidth=1)\n",
        "    sns.boxplot(x=data[x], y=data[y], ax=ax[2])\n",
        "    sns.stripplot(x=data[x], y=data[y], ax=ax[3])\n",
        "    for i in range(4):\n",
        "        ax[i].spines['top'].set_visible(False)\n",
        "        ax[i].spines['right'].set_visible(False)\n",
        "        ax[i].set_xlabel(x, weight='bold', size=20)\n",
        "        ax[i].set_ylabel(y, weight='bold', size=20)\n",
        "        ax[i].set_facecolor(BACKCOLOR)\n",
        "    f.suptitle(f\"{y}'s distribution by {x}\", weight='bold', size=25)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lJOOyi7WpmNe"
      },
      "outputs": [],
      "source": [
        "# ANOVA using permutation test\n",
        "# Image size が ～～～ のエラーが出た場合は logx = True に設定する\n",
        "def anova_perm(data, var, target, logx=False):\n",
        "\n",
        "  # Creating crosstab\n",
        "  crosstb = pd.crosstab(data[var], data[target])\n",
        "\n",
        "  # Creating barplot\n",
        "  # pl = crosstb.plot(kind=\"bar\", stacked=True, rot=0)\n",
        "\n",
        "  for col in data[var].unique():\n",
        "      try:\n",
        "          true_ratio = len(data[(data[var]==col)&(data[target]==True)]) / len(data[data[var]==col])\n",
        "      except:\n",
        "          break\n",
        "      print(col, true_ratio)\n",
        "\n",
        "  observed_variance = data.groupby(var).mean().var()[target] # グループごとの平均値を求め、その平均値の分散を計算している\n",
        "  print('Observed means:', data.groupby(var).mean()[target].values.ravel()) # ravel: 横方向の1次元のベクトルを返す\n",
        "  print('Variance:', observed_variance)\n",
        "  # Permutation test example with stickiness\n",
        "  def perm_test(data):\n",
        "      data = data.copy()\n",
        "      data[target] = np.random.permutation(data[target].values)\n",
        "      return data.groupby(var).mean().var()[target]\n",
        "\n",
        "  random.seed(1)\n",
        "  perm_variance = [perm_test(data) for _ in range(3000)]\n",
        "  print('Pr(Prob)', np.mean([var > observed_variance for var in perm_variance]))\n",
        "\n",
        "  if logx == True:\n",
        "    # 横長のグラフになってしまうので自然対数を取った（通常は下記2行は不要）\n",
        "    observed_variance_log = np.log(observed_variance)\n",
        "    perm_variance_log = np.log(perm_variance)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    ax.hist(perm_variance_log, bins=11, rwidth=0.9)\n",
        "\n",
        "    # 横長のグラフになってしまうので自然対数を取った（通常はxにobserved_varianceを指定）\n",
        "    ax.axvline(x = observed_variance_log, color='black', lw=2)\n",
        "    ax.text(observed_variance, ax.get_ylim()[1]*0.8, 'Observed\\nvariance', bbox={'facecolor':'white'})\n",
        "    ax.set_xlabel('Variance')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  else:\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    ax.hist(perm_variance, bins=11, rwidth=0.9)\n",
        "\n",
        "    ax.axvline(x = observed_variance, color='black', lw=2)\n",
        "    ax.text(observed_variance, ax.get_ylim()[1]*0.8, 'Observed\\nvariance', bbox={'facecolor':'white'})\n",
        "    ax.set_xlabel('Variance')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# column_transformer 利用後のカラム名を取得する関数\n",
        "def get_feature_names(column_transformer):\n",
        "    \"\"\"Get feature names from all transformers.\n",
        "    Returns\n",
        "    -------\n",
        "    feature_names : list of strings\n",
        "        Names of the features produced by transform.\n",
        "    \"\"\"\n",
        "    # Remove the internal helper function\n",
        "    #check_is_fitted(column_transformer)\n",
        "\n",
        "    # Turn loopkup into function for better handling with pipeline later\n",
        "    def get_names(trans):\n",
        "        # >> Original get_feature_names() method\n",
        "        if trans == 'drop' or (\n",
        "                hasattr(column, '__len__') and not len(column)):\n",
        "            return []\n",
        "        if trans == 'passthrough':\n",
        "            if hasattr(column_transformer, '_df_columns'):\n",
        "                if ((not isinstance(column, slice))\n",
        "                        and all(isinstance(col, str) for col in column)):\n",
        "                    return column\n",
        "                else:\n",
        "                    return column_transformer._df_columns[column]\n",
        "            else:\n",
        "                indices = np.arange(column_transformer._n_features)\n",
        "                return ['x%d' % i for i in indices[column]]\n",
        "        if not hasattr(trans, 'get_feature_names'):\n",
        "        # >>> Change: Return input column names if no method avaiable\n",
        "            # Turn error into a warning\n",
        "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
        "                                 \"provide get_feature_names. \"\n",
        "                                 \"Will return input column names if available\"\n",
        "                                 % (str(name), type(trans).__name__))\n",
        "            # For transformers without a get_features_names method, use the input\n",
        "            # names to the column transformer\n",
        "            if column is None:\n",
        "                return []\n",
        "            else:\n",
        "                return [name + \"__\" + f for f in column]\n",
        "\n",
        "        return [name + \"__\" + f for f in trans.get_feature_names()]\n",
        "\n",
        "    ### Start of processing\n",
        "    feature_names = []\n",
        "\n",
        "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
        "    if type(column_transformer) == Pipeline:\n",
        "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
        "    else:\n",
        "        # For column transformers, follow the original method\n",
        "        l_transformers = list(column_transformer._iter(fitted=True))\n",
        "\n",
        "\n",
        "    for name, trans, column, _ in l_transformers:\n",
        "        if type(trans) == Pipeline:\n",
        "            # Recursive call on pipeline\n",
        "            _names = get_feature_names(trans)\n",
        "            # if pipeline has no transformer that returns names\n",
        "            if len(_names)==0:\n",
        "                _names = [name + \"__\" + f for f in column]\n",
        "            feature_names.extend(_names)\n",
        "        else:\n",
        "            feature_names.extend(get_names(trans))\n",
        "\n",
        "    return feature_names\n",
        "# get_feature_names(preprocessor)"
      ],
      "metadata": {
        "id": "kRCCF9crjuF3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_hist(data, xlabel, ylabel):\n",
        "  x = data[xlabel]\n",
        "  y = data[ylabel]\n",
        "\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  gs = gridspec.GridSpec(3, 3)\n",
        "  ax_main = plt.subplot(gs[1:3, :2])\n",
        "  ax_xDist = plt.subplot(gs[0, :2],sharex=ax_main)\n",
        "  ax_yDist = plt.subplot(gs[1:3, 2],sharey=ax_main)\n",
        "\n",
        "  ax_main.scatter(x,y,marker='.')\n",
        "  ax_main.set(xlabel=xlabel, ylabel=ylabel)\n",
        "\n",
        "  ax_xDist.hist(x,bins=100,align='mid')\n",
        "  ax_xDist.set(ylabel='count')\n",
        "  ax_xCumDist = ax_xDist.twinx()\n",
        "  ax_xCumDist.hist(x,bins=100,cumulative=True,histtype='step',density=True,color='r',align='mid')\n",
        "  ax_xCumDist.tick_params('y', colors='r')\n",
        "  ax_xCumDist.set_ylabel('cumulative',color='r')\n",
        "\n",
        "  ax_yDist.hist(y,bins=100,orientation='horizontal',align='mid')\n",
        "  ax_yDist.set(xlabel='count')\n",
        "  ax_yCumDist = ax_yDist.twiny()\n",
        "  ax_yCumDist.hist(y,bins=100,cumulative=True,histtype='step',density=True,color='r',align='mid',orientation='horizontal')\n",
        "  ax_yCumDist.tick_params('x', colors='r')\n",
        "  ax_yCumDist.set_xlabel('cumulative',color='r')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8nYZEi_kz6rJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD1J7WwsQymh"
      },
      "source": [
        "## データのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_qJslWxbx52t"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "all_data = pd.concat([train, test], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZhlwcWViuvU"
      },
      "source": [
        "## target と 自動分類が上手くいかないカラムの設定"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target と 自動分類が上手くいかないカラムの設定\n",
        "target = \"SalePrice\"\n",
        "all_data[\"MSSubClass\"] = all_data[\"MSSubClass\"].astype(\"object\")"
      ],
      "metadata": {
        "id": "KjqbhCuwlh4t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### categorical や numerical の定義"
      ],
      "metadata": {
        "id": "vx9-LrIMFl-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_cat_column_names(df, target):\n",
        "  feature_cols = df.columns.drop(target)\n",
        "  categorical_cols = []\n",
        "  numerical_cols = []\n",
        "  for i in feature_cols:\n",
        "      if df[i].dtype=='object':\n",
        "          categorical_cols.append(i)\n",
        "      else:\n",
        "          numerical_cols.append(i)\n",
        "\n",
        "  return categorical_cols, numerical_cols"
      ],
      "metadata": {
        "id": "7heiTuQJTzjI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BoxCox変換する特徴量を決める"
      ],
      "metadata": {
        "id": "C_PVFbzKHmFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_skewed_column_names(df, numerical_cols, threshold=0.75):\n",
        "  skewed_feats = df[numerical_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
        "  skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
        "  skewness = skewness[skewness.abs() > threshold]\n",
        "  skewness.dropna(inplace=True)\n",
        "  skewed_features = skewness.index.copy()\n",
        "\n",
        "  new_numerical_cols = numerical_cols.copy()\n",
        "  for col in skewed_features:\n",
        "    new_numerical_cols.remove(col)\n",
        "\n",
        "  return skewed_features, new_numerical_cols"
      ],
      "metadata": {
        "id": "ZxwziBzPUvgN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_results(model, train_X, train_y):\n",
        "  model.fit(train_X, train_y)\n",
        "  scores = cross_validate(model, train_X, train_y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise', return_estimator=False) # model の状態を確認したい場合はreturn_estimator をTrueにする\n",
        "  score = mean(scores[\"test_score\"])\n",
        "  print(f\"score = {score}\")\n",
        "  y_pred = model.predict(test_X)\n",
        "  output = pd.DataFrame({'Id': test[\"Id\"],\n",
        "                        'SalePrice': y_pred})\n",
        "\n",
        "  path = \"/content/drive/MyDrive/Colab Notebooks/data/output.csv\"\n",
        "  output.to_csv(path, index=False)\n",
        "  display(output)"
      ],
      "metadata": {
        "id": "R3cR4oSAQgbE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target):\n",
        "  train_len = data.shape[0]-data[target].isna().sum()\n",
        "  train_X = data.iloc[:train_len][data.columns.drop(target)]\n",
        "  train_y = pd.DataFrame(data.iloc[:train_len][target], columns=[target])\n",
        "  test_X = data.iloc[train_len:][data.columns.drop(target)]\n",
        "\n",
        "  return train_X, train_y, test_X"
      ],
      "metadata": {
        "id": "XscJpQKYvDYA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validation function\n",
        "n_folds = 5\n",
        "\n",
        "def get_rmse_CV(model, train_X, train_y):\n",
        "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    scores = cross_validate(model, train_X, train_y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise', return_estimator=False) # model の状態を確認したい場合はreturn_estimator をTrueにする\n",
        "    rmse = np.sqrt(-scores[\"test_score\"])\n",
        "\n",
        "    return(rmse)"
      ],
      "metadata": {
        "id": "HhmK7B_UG6qH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 外れ値に対する処理の定義"
      ],
      "metadata": {
        "id": "g9gx-LGwyYXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CleanOutlier(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, contamination=0, strategy=\"mean\"):\n",
        "        self.contamination = contamination\n",
        "        self.strategy = strategy\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.contamination==0: return self\n",
        "        self.lof = LocalOutlierFactor(contamination=self.contamination, novelty=True)\n",
        "        self.lof.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X_):\n",
        "        X = deepcopy(X_)\n",
        "        if self.contamination==0: return X\n",
        "        idx_outlier = self.lof.predict(X)==-1\n",
        "        X[idx_outlier, :] = np.nan # set NaN to outlier value\n",
        "\n",
        "        simple_imputer = SimpleImputer(strategy=self.strategy)\n",
        "        X = simple_imputer.fit_transform(X) # fill outlier value usin simple_imputer\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "SMPJQDblySzK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmaOutlier(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, sigma=3):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X_):\n",
        "        X = deepcopy(X_)\n",
        "        X = pd.DataFrame(X)\n",
        "        for col in X.columns:\n",
        "          m = np.mean(X[col])\n",
        "          sd = np.std(X[col])\n",
        "          X[X[col]>(sd*self.sigma+m)] = m + sd * self.sigma\n",
        "          X[X[col]<(sd*self.sigma*-1+m)] = m - sd * self.sigma\n",
        "\n",
        "        return X.to_numpy()"
      ],
      "metadata": {
        "id": "Figzq5oTyVhR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 特徴量エンジニアリングの処理の定義"
      ],
      "metadata": {
        "id": "1--IBj9ThaH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(data):\n",
        "  # add new feature\n",
        "  data[\"YearSinceRemodel\"] = data[\"YrSold\"] - data[\"YearBuilt\"] # ここで新しい特徴量を追加する\n",
        "  data['BsmtFinType1_Unf'] = 1*(data['BsmtFinType1'] == 'Unf') # ここで新しい特徴量を追加する\n",
        "  data['HasWoodDeck'] = (data['WoodDeckSF'] == 0) * 1 # ここで新しい特徴量を追加する\n",
        "  data['Total_Home_Quality'] = data['OverallQual'] + data['OverallCond'] # ここで新しい特徴量を追加する\n",
        "  data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF'] # ここで新しい特徴量を追加する\n",
        "  data['has2ndfloor'] = data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0) # ここで新しい特徴量を追加する\n",
        "  data['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0) # ここで新しい特徴量を追加する\n",
        "  data['hasbsmt'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0) # ここで新しい特徴量を追加する\n",
        "  data['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0) # ここで新しい特徴量を追加する\n",
        "  data['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "  data['YrBltAndRemod'] = data['YearBuilt'] + data['YearRemodAdd']\n",
        "  data['Total_sqr_footage'] = (data['BsmtFinSF1'] + data['BsmtFinSF2'] + data['1stFlrSF'] + data['2ndFlrSF'])\n",
        "  data['Total_Bathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) + data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))\n",
        "  data['Total_porch_sf'] = (data['OpenPorchSF'] + data['3SsnPorch'] + data['EnclosedPorch'] + data['ScreenPorch'] + data['WoodDeckSF'])\n",
        "\n",
        "  # delete features\n",
        "  data = data.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
        "  return data"
      ],
      "metadata": {
        "id": "UekuZc7-teEq"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基本的な処理"
      ],
      "metadata": {
        "id": "4JGTB6IKL1kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリング\n",
        "all_data_fe =feature_engineering(all_data_fe)\n",
        "\n",
        "# 量的変数、カテゴリ変数、歪度のある量的変数を定義する\n",
        "categorical_cols, numerical_cols = get_num_cat_column_names(all_data_fe, target)\n",
        "skewed_features, numerical_cols = get_skewed_column_names(all_data_fe, numerical_cols, threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgL7lcWqOV56",
        "outputId": "f99a5b75-e5e7-4f78-e7cd-ff72358734a8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 28914.0510 (3762.9644)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 比較"
      ],
      "metadata": {
        "id": "wfkjhsxaVY3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimpleImputer と KNNImputerの比較 ⇒ ほぼ変化なし"
      ],
      "metadata": {
        "id": "-Prk830ZVbAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリング\n",
        "all_data_fe =feature_engineering(all_data_fe)\n",
        "\n",
        "# 量的変数、カテゴリ変数、歪度のある量的変数を定義する\n",
        "categorical_cols, numerical_cols = get_num_cat_column_names(all_data_fe, target)\n",
        "skewed_features, numerical_cols = get_skewed_column_names(all_data_fe, numerical_cols, threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer_KNN = Pipeline(steps=[('num_imputer', KNNImputer(n_neighbors=5, metric='nan_euclidean')), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer_KNN = Pipeline(steps=[('num_imputer', KNNImputer(n_neighbors=5, metric='nan_euclidean')), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer_KNN = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
        "preprocessor_KNN = ColumnTransformer(transformers=[(\"num\", numeric_transformer_KNN, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer_KNN, categorical_cols), (\"skew\", skewed_transformer_KNN, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline_KNN = Pipeline([\n",
        "    ('preprocessing', preprocessor_KNN),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "score = get_rmse_CV(pipeline_KNN, train_X, train_y)\n",
        "print(\"LGBM(KNN) score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqiV3oQ4VaTi",
        "outputId": "515f6ce2-8dd4-47aa-8263-5cbdfc781ad9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 28914.0510 (3762.9644)\n",
            "\n",
            "LGBM(KNN) score: 28978.3018 (3743.1350)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot と ラベルエンコーディングの比較 ⇒ 良くなった"
      ],
      "metadata": {
        "id": "8cKgowuDX3U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリング\n",
        "all_data_fe =feature_engineering(all_data_fe)\n",
        "\n",
        "# 量的変数、カテゴリ変数、歪度のある量的変数を定義する\n",
        "categorical_cols, numerical_cols = get_num_cat_column_names(all_data_fe, target)\n",
        "skewed_features, numerical_cols = get_skewed_column_names(all_data_fe, numerical_cols, threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer_sub = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer_sub = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer_sub = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "pipeline_sub = ColumnTransformer(transformers=[(\"num\", numeric_transformer_sub, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer_sub, categorical_cols), (\"skew\", skewed_transformer_sub, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline_sub = Pipeline([\n",
        "    ('preprocessing', pipeline_sub),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "score = get_rmse_CV(pipeline_sub, train_X, train_y)\n",
        "print(\"LGBM(sub) score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQt5tebMX7aD",
        "outputId": "e9ccee2a-0b60-473a-b4ef-656fe8d466d2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 28914.0510 (3762.9644)\n",
            "\n",
            "LGBM(sub) score: 28896.5925 (3642.0496)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalerの有無（StandardScaler）⇒ scalerない方が良い"
      ],
      "metadata": {
        "id": "gowj-wm-ZVmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリング\n",
        "all_data_fe =feature_engineering(all_data_fe)\n",
        "\n",
        "# 量的変数、カテゴリ変数、歪度のある量的変数を定義する\n",
        "categorical_cols, numerical_cols = get_num_cat_column_names(all_data_fe, target)\n",
        "skewed_features, numerical_cols = get_skewed_column_names(all_data_fe, numerical_cols, threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler()), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkg8-DG8ZbNB",
        "outputId": "853e5e09-b5fc-4573-c757-61e1c4c7af97"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 28896.5925 (3642.0496)\n",
            "\n",
            "LGBM score: 27998.1664 (3964.8795)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yeo-johnson変換の有無（した方が良い）"
      ],
      "metadata": {
        "id": "hMFoL_9fagAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリングしたものを学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(feature_engineering(all_data_fe), target)\n",
        "\n",
        "# 量的変数、カテゴリ変数、歪度のある量的変数を定義する\n",
        "categorical_cols, numerical_cols = get_num_cat_column_names(all_data_fe, target)\n",
        "skewed_features, numerical_cols = get_skewed_column_names(all_data_fe, numerical_cols, threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, list(set(numerical_cols)-set(skewed_features))), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_features)])\n",
        "\n",
        "# Pipeline を定義する\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 学習用データとテストデータを分ける\n",
        "train_X, train_y, test_X = split_data(all_data_fe, target)\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obx6sasiZ60e",
        "outputId": "c0dba0f7-0a4b-4e00-886f-5d47430c2ee2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 27998.1664 (3964.8795)\n",
            "\n",
            "LGBM score: 28267.8240 (3839.3958)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 外れ値の除外（除外したほうが良い）\n",
        "Best parameters:  {'contamination_num': 0.002148248981503568, 'contamination_skew': 8.630333857546982e-06}\n",
        "Best score:  27925.729263493722"
      ],
      "metadata": {
        "id": "bVT-e5A8bkdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータ最適化の目的関数を定義\n",
        "def objective(trial):\n",
        "    # CleanOutlierのcontaminationの最適化範囲を指定\n",
        "    contamination_num = trial.suggest_loguniform('contamination_num', 1e-7, 0.1)\n",
        "    contamination_skew = trial.suggest_loguniform('contamination_skew', 1e-7, 0.1)\n",
        "\n",
        "    # 数値変数の前処理パイプライン（contaminationを最適化する）\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('num_imputer', SimpleImputer(strategy='median')),\n",
        "        (\"outlier\", CleanOutlier(contamination=contamination_num, strategy=\"mean\"))\n",
        "    ])\n",
        "\n",
        "    # 歪度のある数値変数の前処理パイプライン（contaminationを最適化する）\n",
        "    skewed_transformer = Pipeline(steps=[\n",
        "        ('num_imputer', SimpleImputer(strategy='median')),\n",
        "        (\"outlier\", CleanOutlier(contamination=contamination_skew, strategy=\"mean\")),\n",
        "        (\"power\", PowerTransformer(method='yeo-johnson'))\n",
        "    ])\n",
        "\n",
        "    # カテゴリ変数の前処理パイプライン\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        (\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # 全体の前処理パイプライン\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        (\"num\", numeric_transformer, list(set(numerical_cols) - set(skewed_features))),\n",
        "        (\"cat\", categorical_transformer, categorical_cols),\n",
        "        (\"skew\", skewed_transformer, skewed_features)\n",
        "    ])\n",
        "\n",
        "    # モデルの定義（例：LGBMRegressor）\n",
        "    model = lgb.LGBMRegressor()\n",
        "\n",
        "    # パイプラインを定義\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # パイプラインを評価（例：RMSEをスコアとする）\n",
        "    score = get_rmse_CV(pipeline, train_X, train_y).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "# Optunaによる最適化\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "# 最適なハイパーパラメータとスコアの表示\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value\n",
        "print(\"Best parameters: \", best_params)\n",
        "print(\"Best score: \", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "44b3e9e1c0a948f2a5790a16d265b2b6",
            "a192e28e95284fc0a57789b9866fd5ba",
            "f9c2acc03fef48479d95197ac620e477",
            "6d73ddc3990144ccad3dab5e5d2d7186",
            "b44154088f994c0caf51e5ee3d36ae68",
            "cc674aa2c616440d85541dc0706be3f6",
            "11ebc3fc9cc74adfa2e226cc87a9d77e",
            "05aa7cedc4c94e179adb2d50aa2c6660",
            "1b548763d0da4b14bdcb492d226e6429",
            "55130a55aee242af89815598b46ade5a",
            "a237c67215794aeea59cca4f0c85a3b4"
          ]
        },
        "id": "LGK3LC-OavLF",
        "outputId": "bdaa71ea-75d0-4c64-e0a7-17fbecea579a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44b3e9e1c0a948f2a5790a16d265b2b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'contamination_num': 0.002148248981503568, 'contamination_skew': 8.630333857546982e-06}\n",
            "Best score:  27925.729263493722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 少し改造した基本的なコード"
      ],
      "metadata": {
        "id": "nVvnQ3DgpPmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_variable_types_threshold(df, target, skewness_threshold=0.75):\n",
        "    numeric_cols = []\n",
        "    skewed_cols = []\n",
        "    categorical_cols = []\n",
        "\n",
        "    for column in df.columns.drop(target):\n",
        "        if np.issubdtype(df[column].dtype, np.number):\n",
        "            if abs(skew(df[column])) > skewness_threshold:\n",
        "                skewed_cols.append(column)\n",
        "            else:\n",
        "                numeric_cols.append(column)\n",
        "        elif df[column].dtype == 'object':\n",
        "            categorical_cols.append(column)\n",
        "\n",
        "    return numeric_cols, skewed_cols, categorical_cols"
      ],
      "metadata": {
        "id": "G4DPmxDRdA7w"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering 用のデータフレームを作る\n",
        "all_data_fe = all_data.copy()\n",
        "\n",
        "# 特徴量エンジニアリングしたものを学習用データとテストデータに分ける\n",
        "train_X, train_y, test_X = split_data(feature_engineering(all_data_fe), target)\n",
        "\n",
        "numeric_cols, skewed_cols, categorical_cols = get_variable_types_threshold(feature_engineering(all_data_fe), target, skewness_threshold=0.75)\n",
        "\n",
        "# 特徴量への前処理を行う Preprocessor を定義する\n",
        "numeric_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\"))])\n",
        "skewed_transformer = Pipeline(steps=[('num_imputer', SimpleImputer(strategy=\"median\")), (\"outlier\", CleanOutlier(contamination=0.001, strategy=\"mean\")), (\"power\", PowerTransformer(method='yeo-johnson'))])\n",
        "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, numeric_cols), (\"cat\", categorical_transformer, categorical_cols), (\"skew\", skewed_transformer, skewed_cols)])\n",
        "\n",
        "# Pipelineを定義\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', lgb.LGBMRegressor())\n",
        "])\n",
        "\n",
        "# 作成したPipelineの精度を評価する\n",
        "score = get_rmse_CV(pipeline, train_X, train_y)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwLfTLdPh8ma",
        "outputId": "726eaac1-66ea-42a2-9885-d14c2f9f7907"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM score: 27230.6579 (2715.5045)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}